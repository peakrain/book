## 第4章 并发与同步

本章主要介绍了并发与同步中锁的应用与应当注意的问题。
	
### 4.1并发

#### 引言
	
这几年并发技术受到前所未有的关注：CPU 进入多核时代，连手机芯片都使用三核的CPU(AP+BP+DSP 集成到一颗芯片)了。天生具有并发能力的语言 ErLang 逐渐成为热点。网格和云计算开始进入实用阶段。还有一些新技术更是让我闻所未闻，初学者也不用被这些铺天盖地的名词吓倒。据笔者的经验来看， 这些技术或许能够改变产业的格局，对人类生活造成重大影响，但从实现角度来看并不无多少革命，相反大部分都是传统技术的改进和应用。这几年我一直在研究开 源的基础软件，实际上我没有发现多少“新”东西或者核心技术。
		
要说真正的核心还是如序言中说的：战胜复杂度和应对变化。
		
作为系统程序员，掌握基础理论和经典的设计方法，比去追逐一些所谓的新技术要实用得多，基础打扎实了，学习新知识也是很容易的事。
	
#### 任务：
		
了解linux下的多线程编程的基本方法，以双向链表为载体实现传统的生产者-消费者模型：一个线程往双向链表中加东西，另外一个线程从这里面取。
	
#### 初学者常犯的错误：
		
**(1)用临时变量作为线程参数的问题**

```C
#include <stdio.h>
#include <pthread.h>
#include <assert.h>
void* start_routine(void* param)
{
	char* str = (char*)param;
	printf("%s:%s\n", __func__, str);
	return NULL;
}
pthread_t create_test_thread()
{
	pthread_t id = 0;
	char str[] = "it is ok!";
	pthread_create(&id, NULL, start_routine, str);
	return id;
}
int main(int argc, char* argv[])
{
	void* ret = NULL;
	pthread_t id = create_test_thread();
	pthread_join(id, &ret);
	return 0;
}
```
			
分析：由于新线程和当前线程是并发的，谁先谁后是无法预测的。可能create_test_thread 已经执行完了，str已经被释放了，新线程才拿到这参数，此时它的内容已经无法确定了，打印出的字符串自然是随机的

**(2)线程参数共享的问题**
	
```C
#include <stdio.h>
#include <pthread.h>
#include <assert.h>
void* start_routine(void* param)
{
	int index = *(int*)param;
	printf("%s:%d\n", __func__, index);
	return NULL;
}
#define THREADS_NR 10
void create_test_threads()
{
	int i = 0;
	void* ret = NULL;
	pthread_t ids[THREADS_NR] = {0};
	for(i = 0; i < THREADS_NR; i++)
	{
		pthread_create(ids + i, NULL, start_routine, &i);
	}
	for(i = 0; i < THREADS_NR; i++)
	{
		pthread_join(ids[i], &ret);
	}
	return ;
}
int main(int argc, char* argv[])
{
	create_test_threads();
	return 0;
}
```
	
分析：由于新线程和当前线程是并发的，谁先谁后是无法预测的。i在不断变化，所以新线程拿到的参数值是无法预知的，打印出的字符串自然也是随机

**(3)虚假并发**
	
```C
#include <stdio.h>
#include <pthread.h>
#include <assert.h>
void* start_routine(void* param)
{
	int index = *(int*)param;
	printf("%s:%d\n", __func__, index);
	return NULL;
}
#define THREADS_NR 10
void create_test_threads()
{
	int i = 0;
	void* ret = NULL;
	pthread_t ids[THREADS_NR] = {0};
	for(i = 0; i < THREADS_NR; i++)
	{
		pthread_create(ids + i, NULL, start_routine, &i);
		pthread_join(ids[i], &ret);
	}
	return ;
}
int main(int argc, char* argv[])
{
	create_test_threads();
	return 0;
}
```
	
分析：因为pthread_join会阻塞直到线程退出，所以这些线程实际上是串行执行的，一个退出了，才创建下一个。当年一个同事写了一个多线程的测试程序，就是这样写的，结果没有测试出一个潜伏的问题，直到产品运行时，这个问题才暴露出来。
	

访问线程共享的数据时要加锁，让访问串行化，否则就会出问题。比如，可能你正在访问的双向链表的某个结点时，它已经被另外一个线程删掉了。加锁的方 式有很多种，像互斥锁(mutex= mutual exclusive lock)，信号量(semaphore)和自旋锁(spin lock)等都是常用的，它们的使用同样很简单，我们就不多说了。

#### 在加锁/解锁时，初学者常犯两个错误：

**(1)存在遗漏解锁的路径。**
	
初学者常见的做法就是，进入某个临界函数时加锁，在函数结尾的地方解锁，甚至出现这种写法：
	
```C
{
	/*这里加锁*/
	…
	return …;
	/*这里解锁*/
}
```

如果你也犯了这种错误，应该好好反思一下。有时候，return的地方太多，在某一处忘记解锁是可能的，就像内存泄露一样，只是忘记解锁的后果更严重。

```C
Ret dlist_insert(DList* thiz, size_t index, void* data)
{
	DListNode* node = NULL;
	DListNode* cursor = NULL;
	return_val_if_fail(thiz != NULL, RET_INVALID_PARAMS);
	dlist_lock(thiz);
	if((node = dlist_create_node(thiz, data)) == NULL)
	{
		dlist_unlock(thiz);
		return RET_OOM;
	}
	if(thiz->first == NULL)
	{
		thiz->first = node;
		dlist_unlock(thiz);
		return RET_OK;
	}
	...
	dlist_unlock(thiz);
	return RET_OK;
}
```
	
如果一个函数有五六个甚至更多的地方返回，遗忘一两个地方是很常见的，即使没有忘记，每个返回的地方都要去解锁和释放相关资源也是很麻烦的。
在这种情况下，我们最好是**实现单入口单出的函数**，常见的做法有两种：

**(1)使用goto语句（在linux内核里大量使用）**
	
```C
Ret dlist_insert(DList* thiz, size_t index, void* data)
{
	Ret ret = RET_OK;
	DListNode* node = NULL;
	DListNode* cursor = NULL;
	return_val_if_fail(thiz != NULL, RET_INVALID_PARAMS);
	dlist_lock(thiz);
	if((node = dlist_create_node(thiz, data)) == NULL)
	{
		ret = RET_OOM;
		goto done;
	}
	if(thiz->first == NULL)
	{
		thiz->first = node;
		goto done;
	}
	...
	done:
	dlist_unlock(thiz);
	return ret;
}
```
	
**(2)使用do{}while(0);语句，出于受教科书的影响(不要用goto语句)，我习惯了这种做法。**
	
```C
Ret dlist_insert(DList* thiz, size_t index, void* data)
{
	Ret ret = RET_OK;
	DListNode* node = NULL;
	DListNode* cursor = NULL;
	return_val_if_fail(thiz != NULL, RET_INVALID_PARAMS);
	dlist_lock(thiz);
	do
	{
		if((node = dlist_create_node(thiz, data)) == NULL)
		{
			ret = RET_OOM;
			break;
		}
		if(thiz->first == NULL)
		{
			thiz->first = node;
			break;
		}
		...
	}while(0);
	dlist_unlock(thiz);
	return ret;
}
```
	
**(2)加锁顺序的问题**
	
有时候为了提高效率，常常降低加锁的粒度，访问时不是用一个锁锁住整个数据结构，而是用多个锁来控制数据结构各个部分。这样一个线程访问 数据结构的这部分时，另外一个线程还可以访问数据结构的其它部分。但是在有的情况下，你需要同时锁几个锁，这时就要注意了：所有线程一定要按相同的顺序加锁，相反的顺序解锁。否则就可能出现死锁，两个线程都拿到对方需要的锁，结果出现互相等待的情况。

### 4.2同步

在生产者-消费者的练习中，大部分人选择了由调用者来加锁：作为生产者，往双向链表里插入数据时，先加锁，插入数据，然后解锁。作为消费者，从双向链表里取 数据时，先加锁，删除数据，然后解锁。

这是合理的，不过有点麻烦：

每个调用者都要做这些动作，如果其中一个调用者忘记了解锁的步骤，就会造成死锁。

而且调用者必须要清楚自己是在多线程下工作，这些代码放到单线程的环境中就不能使用了。

在很多情况下由实现者来加锁是比较好的选择，那样对调用者更为友好，可以避免出现一些不必要的错误。比如像目前Linux下流行的DBUS，它是一 套进程间通信框架，它支持单线程和多线程版本，但调用者不需要明确加锁/解锁，也不需要连接不同的库或者用宏来控制，单线程版本和多线程版本的不同只是在 一个初始化函数上。

对前面实现的双向链表做点改进：

（1）**支持多线程和单线程版本**。对于多线程版本，由实现者(在链表)加锁/解锁，对于单线程版本，其性能不受影响(或很小)。

（2）区分单线程版本和多线程版本时，不需要链接不同的库，或者要宏来控制，完全可以在运行时切换。

（3）保持双向链表的通用性，不依赖于特定的平台。

面对这个需求，一些初学者可能有点蒙了。以前在学校的时候，对于课本后面的练习，我总是信心百倍，原因很简单，我确信这些练习不管它的出现方式有多么不同， 但总是与前面学过的知识有关。记得《如何求解问题—现代启发式方法》中说过，正是这种练习的方式妨碍了我们解决问题的能力，在现实中解决问题时通常没有这 么幸运。在《系统程序员成长计划》我把练习放前面，目标就是刺激读者去思考，在学习知识的同时学习解决问题的方法。
这里我们应该怎么分析呢？要在双向链表里加锁，第一是要区分单线程和多线程，要链接同一个库，而且不能用宏来控制。第二是不能依赖于特定平台，而锁本身恰恰又是依赖于平台的。怎么办？很明显这两个需求都要求锁的实现可以变化的：单线程版本它什么都不做，多线程版本中，不同的平台有不同的实现。

我们要做的就是隔离变化。变化怎么隔离？前面我们已经练习过几次用回调函数来隔离变化了，所有的读者都会想到这个方法，因为锁无非是具有两个功能：加锁和解锁，我们把它抽象成两个回调函数就行了。
这种方法是可行的。这里的情况与前面相比有点特殊：前面的回调函数都是些独立功能的函数，每个回调函数都有自己的上下文，而这里的多个回调函数具有相关的功能，并且共享同一个上下文(锁)。其次是这里的上下文(锁)是一个对象，有自己的生命周期，完成自己的使命后就应该被销毁。

这里我们引入**接口(interface)**这个术语，接口其实就是一个抽象的概念，它只定义调用者和实现者之间的契约，而不规定实现的方法。比如这里的锁就是一个抽象的概念，它有加锁/解锁两个功能，这是调用者和实现者之间的契约。但光有这个概念不能做任何事情，只有具体的锁才能被使用。至于具体的锁，不同的平台有不同的实现，但调用者不用关心。正因为调用者不用关心接口的实现方法，接口成了隔离变化最有力的武器。

在这里，锁是一个接口，双向链表是锁的调用者，有基于不同方式实现的锁。通过接口，双向链表把锁的变化隔离开来：区分单线程和多线程，隔离平台相关性。在C语言中，接口的朴素定义是：一组相关的回调函数及其共享的上下文。

接口怎么定义：
```C
struct _Locker;
typedef struct _Locker Locker;
typedef Ret (*LockerLockFunc)(Locker* thiz);
typedef Ret (*LockerUnlockFunc)(Locker* thiz);
typedef void (*LockerDestroyFunc)(Locker* thiz);
struct _Locker
{
	LockerLockFunc lock;
	LockerUnlockFunc unlock;
	LockerDestroyFunc destroy;
	char priv[0];
};
```
#### 要注意的三个问题：

（1）**接口一定要足够抽象，不能依赖任何具体实现的数据类型。**
	接口一旦与某个具体实现关联了，另外一种实现就会遇到麻烦。比如这里你使用了pthread_mutex_t，那你要实现一个win32下的锁怎么办呢。

（2）**接口不能有create函数，但一定要有destroy函数。**
	我们说过对象有自己的生命周期，创建它，使用它，然后销毁它。但接口只是一个概念，不可能通 过这个概念凭空创建一个对象出来，对象只能通过具体实现来创建，所以接口不应该出现create自己的函数。一旦对象被创建出来，使用者应该在不再需要它 时销毁它，在销毁对象时，如果还要知道它的实现方式才能销毁它，那就造成了调用者和实现者之间不必要的耦合，因此接口都要提供一个destroy函数，调用者可以直接销毁它。

（3）**这里的priv用来存放上下文信息，也就是具体实现需要用到的数据结构。**

像前面的回调函数一样，我们可以用一个void* ctx的成员来保存上下文信息。
	
**我们使用的char priv[0];**
	
技巧，有点额外的好处：**只需要一次内存分配，而且可以分配刚好够用的长度(0到任意长度)。**

前面我们使用回调函数，调用时要判断回调函数是否为空，每个地方都要重复这个动作，所以我们把这些判断集中起来好了：
```c
static inline Ret locker_lock(Locker* thiz)
{
	return_val_if_fail(thiz != NULL && thiz->lock != NULL, RET_INVALID_PARAMS);
	return thiz->lock(thiz);
}

static inline Ret locker_unlock(Locker* thiz)
{
	return_val_if_fail(thiz != NULL && thiz->unlock != NULL, RET_INVALID_PARAMS);
	return thiz->unlock(thiz);
}

static inline void locker_destroy(Locker* thiz)
{
	return_if_fail(thiz != NULL && thiz->destroy != NULL);
	thiz->destroy(thiz);
	return;
}
```

#### 基于pthread_mutex的实现：

（1）在locker_pthread.h中，提供一个创建函数。

`Locker* locker_pthread_create(void);`

（2）在locker_pthread.c中，实现这些回调函数。

定义私有数据结构：
```C
typedef struct _PrivInfo
{
	pthread_mutex_t mutex;
}PrivInfo;
```
创建对象：
```C
Locker* locker_pthread_create(void)
{
	Locker* thiz = (Locker*)malloc(sizeof(Locker) + sizeof(PrivInfo));
	if(thiz != NULL)
	{
		PrivInfo* priv = (PrivInfo*)thiz->priv;
		thiz->lock = locker_pthread_lock;
		thiz->unlock = locker_pthread_unlock;
		thiz->destroy = locker_pthread_destroy;
		pthread_mutex_init(&(priv->mutex), NULL);
	}
	return thiz;
}
```
实现几个回调函数：
```C
static Ret locker_pthread_lock(Locker* thiz)
{
	PrivInfo* priv = (PrivInfo*)thiz->priv;
	int ret = pthread_mutex_lock(&priv->mutex);
	return ret == 0 ? RET_OK : RET_FAIL;
}
…
```

我简单说一下里面几个问题：

（1）malloc(sizeof(Locker) + sizeof(PrivInfo)); **前面的char priv[0]并不占空间，这是C语言新标准定义的，用于实现变长的buffer，它在这里的长度由sizeof(PrivInfo)决定。**

（2）PrivInfo* priv = (PrivInfo*)thiz->priv; 这里的thiz->priv只是一个定位符，实际上等于(size_t)thiz+sizeof(Locker)，帮我们定位到私有数据的内存地址上。

#### 使用方法：
**单线程版本**：

``DList* dlist = dlist_create(NULL, NULL, locker_pthread_create());

**多线程版本**：

``DList* dlist = dlist_create(NULL, NULL, NULL);

**接口在软件设计中占有非常重要的地位，它是隔离变化和降低复杂度最有力的武器，差不多所有的设计模式都与接口有关。**

### 4.3嵌套与装饰模式

在生产者-消费者的练习中，当由双向链表的实现者负责加锁时，一般都会遇到莫名其妙的死锁问题。

有的读者可能已经查出来了原因是嵌套的加锁。比如在 dlist_insert中调用了dlist_length，进入dlist_insert时已经加了一次锁，再调用dlist_length时又加了一 次锁，这
时就出现了死锁问题。

初学者遇到这个问题的时候，通常的做法是在调用dlist_length之前先解锁，调用完dlist_length后再重新加锁。

这样是存在问题的：一个原子操作变成了几个原子操作，数据完整性得不到保证，在你重新加锁之前，其它线程可能利用这个空隙做了些别的事情。

有效解决这个问题的办法有两个:

其一是**实现一个内部版本的dlist_length，它在里面不加锁**。

其二是**使用嵌套锁，允许同一个线程多次加锁**。 

pthread有嵌套锁的实现，不过我们在这里不用它，原因是我们要提供一个更通用的解决方案。现在我们不再满足于实现一个双向链表，而是要实现一个跨平台的基础函数库。

在这里我们请读者实现一个嵌套锁，要求如下：

**（1）嵌套锁仍然兼容Locker接口。**

**（2）嵌套锁的实现不依赖于特定平台。**

**嵌套锁的实现算法**

**加锁：**

（1）如果没有任何线程加锁，就直接加锁，并且记录下当前线程的ID。

（2）如果是当前线程加过锁了，就不用加锁了，只是将加锁的计数增加一。

（3）如果其它线程加锁了，那就等待直到加锁成功，后继步骤与第一种情况相同。

**解锁：**

（1）如果不是当前线程加的锁或者没有人加锁，那这是错误的调用，直接返回。

（2）如果是当前线程加锁了，将加锁的计数减一。如果计数大于0，说明当前线程加了多次，直接返回就行了。如果计数为0，说明当前线程只加了一次，则执行解锁动作。

这个逻辑很简单，要做到兼容Locker的接口和平台无关，我们还需要引入装饰模式这个概念。装饰模式的功能是在于不改变对象的本质(接口)的前提 下，给对象添加附加的功能。

和继承不同的是，它不是针对整个类的，而只是针对单个对象的。

装饰这个名字非常直观的表现它的意义：在你自己的显示器上做点了装饰，比如贴上一张卡通画：第一是它没有改
显示器的本质，显示器还是显示器。第二是只有你自己的显示器上多了张卡通画，其它显示器没有影响。

这里我们要对一把锁进行装饰，不改变它的接口，但给它加上嵌套的功能。下面我们看看在C语言里的实现方法：

**（1）创建函数的原型。**由于获取当前线程ID的函数是平台相关的，我们要用回调函数来抽象它。
```
typedef int (*TaskSelfFunc)(void);
Locker* locker_nest_create(Locker* real_locker, TaskSelfFunc task_self);
```

这里可以看出：传入的是一把锁，返回的还是一把锁，没有改变的接口，但是返回的锁已经具有嵌套调用的功能了。

**（2）嵌入锁的实现。**
私有信息：拥有锁的线程ID、加锁的计数，被装饰的锁和获取当前线程ID的回调函数。
```C
typedef struct _PrivInfo
{
	int owner;
	int refcount;
	Locker* real_locker;
	TaskSelfFunc task_self;
}PrivInfo;
```

1.实现加锁函数：如果当前线程已经加锁，只是增加加锁计数，否则就加锁。
```C
static Ret locker_nest_lock(Locker* thiz)
{
	Ret ret = RET_OK;
	PrivInfo* priv = (PrivInfo*)thiz->priv;
	if(priv->owner == priv->task_self())
	{
		priv->refcount++;
	}
	else
	{
		if( (ret = locker_lock(priv->real_locker)) == RET_OK)
		{
			priv->refcount = 1;
			priv->owner = priv->task_self();
		}
	}
	return ret;
}
```C

2.实现解锁函数：只有当前线程加的锁才能解锁，先减少加锁计数，计数为0时才真正解锁，否则直接返回。
```C
static Ret locker_nest_unlock(Locker* thiz)
{
	Ret ret = RET_OK;
	PrivInfo* priv = (PrivInfo*)thiz->priv;
	return_val_if_fail(priv->owner == priv->task_self(), RET_FAIL);
	priv->refcount--;
	if(priv->refcount == 0)
	{
		priv->owner = 0;
		ret = locker_unlock(priv->real_locker);
	}
	return ret;
}
```

####使用方法:

除了创建方法稍有不同外，调用方法完全一样。
```
Locker* locker = locker_pthread_create();
Locker* nest_locker = locker_nest_create(locker, (TaskSelfFunc)pthread_self);
DList* dlist = dlist_create(NULL, NULL, nest_locker);
```

装饰模式最有用的地方在于，它给单个对象增加功能，但不是影响调用者，即使加了多级装饰，调用者也不用关心。


### 4.4读写锁

在前面的实现中，像dlist_length这类的查询函数也要加锁，那样才能保证在查询过程中对象的状态不会被其它线程所改变。加锁阻止了其它线 程修改对象，也阻止其它线程查询对象。

如果大多数情况下，线程只是查询对象的状态而不修改它，这种设计不是一种高效的方法，因为它不允许多个线程同时查 询。我们能不能实现一种锁，它能串行化对数据结构的修改，

而同时支持并行的查询呢？

这就是所谓的读写锁，也称为共享-互斥锁。这种锁在数据库管理系统中(DBMS)和操作系统内核中大量应用，作为系统程序员，了解它的实现机制是有必要的。这里我们请读者实现读
写锁，要求如下：

**（1）不依赖于特定平台。**

**（2）在任何情况下都不带来额外的性能开销。**

记住多想多练不要偷懒，学习知识点不是我们最重要的目标，知识点能帮你解决别人解决过的问题，但对你解决新问题未必有多大好处，真正的程序员不应当只是解决问题方案的贩卖者。不断从思考中学习解决问题的方法，加上灵活应用已经掌握的知识点，你的设计水平才会大大提高，这也是《系统程序员成长计划》努力的目标。

读写锁在加锁时，要区分是为了读而加锁还是为了写而加锁，所以和递归锁不同的是，它无法兼容Locker接口了。不过为了做到不依赖于特定平台，我们可以利用Locker的接口来抽象锁的实现。利用现有的锁来实现读写锁。读写锁的可变的部分已经被Locker隔离了，所以读写锁本身不需要做成接口。它只是一个普通对象而已：
```C
struct _RwLocker;
typedef struct _RwLocker RwLocker;
RwLocker* rw_locker_create(Locker* rw_locker, Locker* rd_locker);
Ret rw_locker_wrlock(RwLocker* thiz);
Ret rw_locker_rdlock(RwLocker* thiz);
Ret rw_locker_unlock(RwLocker* thiz);
void rw_locker_destroy(RwLocker* thiz);
```

**创建读写锁**
```C
RwLocker* rw_locker_create(Locker* rw_locker, Locker* rd_locker)
{
	RwLocker* thiz = NULL;
	return_val_if_fail(rw_locker != NULL && rd_locker != NULL, NULL);
	thiz = (RwLocker*)malloc(sizeof(RwLocker));
	if(thiz != NULL)
	{
	thiz->readers = 0;
	thiz->mode = RW_LOCKER_NONE;
	thiz->rw_locker = rw_locker;
	thiz->rd_locker = rd_locker;
	}
	return thiz;
}
```

读写锁的基本要求是：写的时候不允许任何其它线程读或者写，读的时候允许其它线程读，但不允许其它线程写。所以在实现时，写的时候一定要加锁，第一个读的线程要加锁，后面其它线程读时，只是增加锁的引用计数。我们需要两个锁：一个锁用来保存被保护的对象，一个锁用来保护引用计数。

**加写锁**
```C
Ret rw_locker_wrlock(RwLocker* thiz)
{
	Ret ret = RET_OK;
	return_val_if_fail(thiz != NULL, RET_INVALID_PARAMS);
	if((ret = locker_lock(thiz->rw_locker)) == RET_OK)
	{
		thiz->mode = RW_LOCKER_WR;
	}
	return ret;
}
```

加写锁很简单，直接加保护受保护对象的锁，然后修改锁的状态为已加写锁。后面其它的线程想写，就会这个锁上等待，如果想读也要等待(见后面)。

**加读锁**
Ret rw_locker_rdlock(RwLocker* thiz)
{
	Ret ret = RET_OK;
	return_val_if_fail(thiz != NULL, RET_INVALID_PARAMS);
	if((ret = locker_lock(thiz->rd_locker)) == RET_OK)
	{
		thiz->readers++;
		if(thiz->readers == 1)
		{
			ret = locker_lock(thiz->rw_locker);
			thiz->mode = RW_LOCKER_RD;
		}
		locker_unlock(thiz->rd_locker);
	}
	return ret;
}

先尝试加保护引用计数的锁，增加引用计数。如果当前线程是第一个读，就要去加保护受保护对象的锁。如果此时已经有线程在写，就等待直到加锁成功，然后把锁的状态设置为已加读锁，最后解开保护引用计数的锁。

**解锁**
```C
Ret rw_locker_unlock(RwLocker* thiz)
{
	Ret ret = RET_OK;
	return_val_if_fail(thiz != NULL, RET_INVALID_PARAMS);
	if(thiz->mode == RW_LOCKER_WR)
	{
		thiz->mode == RW_LOCKER_NONE;
		ret = locker_unlock(thiz->rw_locker);
	}
	else
	{
		assert(thiz->mode == RW_LOCKER_RD);
		if((ret = locker_lock(thiz->rd_locker)) == RET_OK)
		{
			thiz->readers--;
			if(thiz->readers == 0)
			{
				thiz->mode == RW_LOCKER_NONE;
				ret = locker_unlock(thiz->rw_locker);
			}
			locker_unlock(thiz->rd_locker);
		}
	}
	return ret;
}
```

解锁时根据状态来决定，解写读直接解保护受保护对象的锁。解读锁时，先要加锁保护引用计数的锁，引用计数减一。如果自己是最后一个读，才解保护受保护对象的锁，最后解开保护引用计数的锁。

从上面读写锁的实现，我们可以看出，读写锁要充分发挥作用，就要基于两个假设：

**（1）读写的不对称性，读的次数远远大于写的次数。**

像数据库就是这样，决大部分时间是在查询，而修改的情况相对少得多，所以数据库通常使用读写锁。

**（2）处于临界区的时间比较长。**

从上面的实现来看，读写锁实际上比正常加/解锁的次数反而要多，如果处于临界区的时间比较短，比如和修改引用计数差不多，使用读写锁，即使全部是读，它的效率也会低于正常锁。


### 4.5无锁的数据结构

提到并行计算通常都会想到加锁，事实却并非如此，大多数并发是不需要加锁的。比如在不同电脑上运行的代码编辑器，两者并发运行不需要加锁。在一台电脑上同时运行的媒体播放放器和代码编辑器，两者并发运行不需要加锁(当然系统调用和进程调度是要加锁的)。在同一个进程中运行多个线程，如果各自处理独立的事情也不需要加锁(当然系统调用、进程调度和内存分配是要加锁的)。在以上这些情况里，各个并发实体之间没有共享数据，所以虽然并发运行但不需要加锁。

多线程并发运行时，虽然有共享数据，如果所有线程只是读取共享数据而不修改它，也是不用加锁的，比如代码段就是共享的“数据”，每个线程都会读取，但是不用加锁。排除所有这些情况，多线程之间有共享数据，有的线程要修改这些共享数据，有的线程要读取这些共享数据，这才是程序员需要关注的情况，也是本节我们讨论的范围。

在并发的环境里，加锁可以保护共享的数据，但是加锁也会存在一些问题：

**（1）由于临界区无法并发运行，进入临界区就需要等待，加锁带来效率的降低。**

**（2）在复杂的情况下，很容易造成死锁，并发实体之间无止境的互相等待。**

**（3）在中断/信号处理函数中不能加锁，给并发处理带来困难。**

**（4）优先级倒置造成实时系统不能正常工作。低级优先进程拿到高优先级进程需要的锁，结果是高/低优先级的进程都无法运行，中等优先级的进程可能在狂跑。**

由于并发与加锁(互斥)的矛盾关系，无锁数据结构自然成为程序员关注的焦点，这也是本节要介绍的：

**（1） CPU提供的原子操作。**

大约在七八年前，我们用apache的xerces来解析XML文件，奇怪的是多线程反而比单线程慢。他们找了很久也没有找出原因，只是证实使用多进程代替多线程会快一个数量级，在
Windows上他们就使用了多进程的方式。后来移植到linux时候，我发现xerces每创建一个结点都会去更新一些全局的统计信息，比如把结点的总数加一，它使用的pthread_mutex实现互斥。这就是问题所在：一个XML文档有数以万计的结点，以50个线程并发为例，每个线程解析一个XML文档，总共要进行上百万次的加锁/解锁，几乎所有线程都在等待，你说能快得了吗？
当时我知道Windows下有InterlockedIncrement之类的函数，它们利用CPU一些特殊指令，保证对整数的基本操作是原子的。 查找了一些资源发现Linux下也有类似的函数，后来我把所有加锁去掉，换成这些原子操作，速度比多进程运行还快了几倍。下面我们看++和--的原子操作在 IA架构上的实现：
```C
#define ATOMIC_SMP_LOCK "lock ; "
typedef struct { volatile int counter; } atomic_t;
static __inline__ void atomic_inc(atomic_t *v)
{
	__asm__ __volatile__(
	ATOMIC_SMP_LOCK "incl %0"
	:"=m" (v->counter)
	:"m" (v->counter));
}
static __inline__ void atomic_dec(atomic_t *v)
{
	__asm__ __volatile__(
	ATOMIC_SMP_LOCK "decl %0"
	:"=m" (v->counter)
	:"m" (v->counter));
}
```

**（2）单入单出的循环队列。**

单入单出的循环队列是一种特殊情况，虽然特殊但是很实用，重要的是它不需要加锁。这里的单入是指只有一个线程向队列里追加数据 (push)，单出只是指只有一个线程从队列里取数据(pop)，循环队列与普通队列相比，不同之处在于它的最大数据储存量是事先固定好的，不能动态增长。尽管有这些限制它的应用还是相当广泛的。这我们介绍一下它的实现：
数据下定义如下：
```C
typedef struct _FifoRing
{
	int r_cursor;
	int w_cursor;
	size_t length;
	void* data[0];
}FifoRing;
```
r_cursor指向队列头，用于取数据(pop)。w_cursor指向队列尾，用于追加数据(push)。length表示队列的最大数据储存量，data表示存放的数据，[0]在这里表示变长的缓冲区(前面我们已经讲过)。

创建函数
```C
FifoRing* fifo_ring_create(size_t length)
{
	FifoRing* thiz = NULL;
	return_val_if_fail(length > 1, NULL);
	thiz = (FifoRing*)malloc(sizeof(FifoRing) + length * sizeof(void*));
	if(thiz != NULL)
	{
		thiz->r_cursor = 0;
		thiz->w_cursor = 0;
		thiz->length = length;
	}
	return thiz;
}
```

这里我们要求队列的长度大于1而不是大于0，为什么呢？排除长度为1的队列没有什么意义的原因外，更重要的原因是队列头与队列尾重叠 (r_cursor= =w_cursor) 时，到底表示是满队列还是空队列？这个要搞清楚才行，上次一个同事犯了这个错误，让我们查了很久。这里我们认为队列头与队列尾重叠时表示队列为空，这与队列初始状态一致，后面在写的时候始终保留一个空位，避免队列头与队列尾重叠，这样可以消除歧义了。

**追加数据(push)**
```C 
Ret fifo_ring_push(FifoRing* thiz, void* data)
{
	int w_cursor = 0;
	Ret ret = RET_FAIL;
	return_val_if_fail(thiz != NULL, RET_FAIL);
	w_cursor = (thiz->w_cursor + 1) % thiz->length;
	if(w_cursor != thiz->r_cursor)
	{
		thiz->data[thiz->w_cursor] = data;
		thiz->w_cursor = w_cursor;
		ret = RET_OK;
	}
	return ret;
}
```

队列头和队列尾之间还有一个以上的空位时就追加数据，否则返回失败。

**取数据(pop)**
```C
Ret fifo_ring_pop(FifoRing* thiz, void** data)
{
	Ret ret = RET_FAIL;
	return_val_if_fail(thiz != NULL && data != NULL, RET_FAIL);
	if(thiz->r_cursor != thiz->w_cursor)
	{
		*data = thiz->data[thiz->r_cursor];
		thiz->r_cursor = (thiz->r_cursor + 1)%thiz->length;
		ret = RET_OK;
	}
	return ret;
}
```

队列头和队列尾不重叠表示队列不为空，取数据并移动队列头。

**单写多读的无锁数据结构。**

单写表示只有一个线程去修改共享数据结构，多读表示有多个线程去读取共享数据结构。前面介绍的读写锁可以有效的解决这个问题，但更高效的办法是使用无锁数据结构。思路如下：
就像为了避免显示闪烁而使用的双缓冲一样，我们使用两份数据结构，一份数据结构用于读取，所有线程都可以在不加锁的情况下读取这个数据结构。另外一份数据结构用于修改，由于只有一个线程会修改它，所以也不用加锁。

在修改之后，我们再交换读/写的两个函数结构，把另外一份也修改过来，这样两个数据结构就一致了。在交换时要保证没有线程在读取，所以我们还需要一个读线程的引用计数。现在我们看看怎么把前面写的双向链表改为单写多读的无锁数据结构。

为了保证交换是原子的，我们需要一个新的原子操作CAS(compare and swap)。
#define CAS(_a, _o, _n) \
({ __typeof__(_o) __o = _o; \
__asm__ __volatile__( \
"lock cmpxchg %3,%1" \
: "=a" (__o), "=m" (*(volatile unsigned int *)(_a)) \
: "0" (__o), "r" (_n) ); \
__o; \
})


数据结构
```C 
typedef struct _SwmrDList
{
	atomic_t rd_index_and_ref;
	DList* dlists[2];
}SwmrDList;
```

两个链表，一个用于读一个用于写。rd_index_and_ref的最高字节记录用于读取的双向链表的索引，低24位用于记录读取线程的引用记数，最大支持16777216个线程同时读取，应该是足够了，所以后面不考虑它的溢出。

**读取操作**
int swmr_dlist_find(SwmrDList* thiz, DListDataCompareFunc cmp, void* ctx)
{
	int ret = 0;
	return_val_if_fail(thiz != NULL && thiz->dlists != NULL, -1);
	atomic_inc(&(thiz->rd_index_and_ref));
	size_t rd_index = (thiz->rd_index_and_ref.counter>>24) & 0x1;
	ret = dlist_find(thiz->dlists[rd_index], cmp, ctx);
	atomic_dec(&(thiz->rd_index_and_ref));
	return ret;
}

**修改操作**
```C
Ret swmr_dlist_insert(SwmrDList* thiz, size_t index, void* data)
{
	Ret ret = RET_FAIL;
	DList* wr_dlist = NULL;
	return_val_if_fail(thiz != NULL && thiz->dlists != NULL, ret);
	size_t wr_index = !((thiz->rd_index_and_ref.counter>>24) & 0x1);
	if((ret = dlist_insert(thiz->dlists[wr_index], index, data)) == RET_OK)
	{
		int rd_index_old = thiz->rd_index_and_ref.counter & 0xFF000000;
		int rd_index_new = wr_index << 24;
		do
		{
			usleep(100);
		}while(CAS(&(thiz->rd_index_and_ref), rd_index_old, rd_index_new));
		wr_index = rd_index_old>>24;
		ret = dlist_insert(thiz->dlists[wr_index], index, data);
	}
	return ret;
}

先修改用于修改的双向链表，修改完成之后等到没有线程读取时，交换读/写两个链表，再修改另一个链表，此时两个链表状态保持一致。

稍做改进，对修改的操作进行加锁，就可以支持多读多写的数据结构，读是无锁的，写是加锁的。

真正的无锁数据结构。Andrei Alexandrescu的《Lock-FreeDataStructures》估计是这方面最经典的论文了，对他的方法我开始感到惊奇后来感到失望，惊奇的是算法的巧妙，失望的是无锁的限制和代价。作者最后说这种数据结构只适用于WRRMBNTM(Write-Rarely-Read-
Many -But-Not-Too-Many)的情况。而且每次修改都要拷贝整个数据结构（甚至多次），所以不要指望这种方法能带来多少性能上的提高，唯一的好处 是能避免加锁带来的部分副作用。有兴趣的朋友可以看下这篇论文，这里我就不重复了。
